{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('display.max_columns', None)\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test  = pd.read_csv(\"Test.csv\")\n",
    "sub = pd.read_excel(\"Sample_submission.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>HostCountry</th>\n",
       "      <th>Team1_Venue</th>\n",
       "      <th>Team2_Venue</th>\n",
       "      <th>Team1_Innings</th>\n",
       "      <th>Team2_Innings</th>\n",
       "      <th>MonthOfMatch</th>\n",
       "      <th>MatchWinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>Second</td>\n",
       "      <td>First</td>\n",
       "      <td>Dec</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Sep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Feb</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Aug</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1  Team2  Stadium  HostCountry Team1_Venue Team2_Venue Team1_Innings  \\\n",
       "0      5      4       37            4        Home        Away        Second   \n",
       "1      1     14       84            7     Neutral     Neutral         First   \n",
       "2      9     15       47            9        Home        Away         First   \n",
       "3      7      2      102            6        Home        Away         First   \n",
       "4      6      8       46            5        Home        Away         First   \n",
       "\n",
       "  Team2_Innings MonthOfMatch  MatchWinner  \n",
       "0         First          Dec            4  \n",
       "1        Second          Sep            1  \n",
       "2        Second          Feb            9  \n",
       "3        Second          Aug            2  \n",
       "4        Second          Aug            6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>HostCountry</th>\n",
       "      <th>Team1_Venue</th>\n",
       "      <th>Team2_Venue</th>\n",
       "      <th>Team1_Innings</th>\n",
       "      <th>Team2_Innings</th>\n",
       "      <th>MonthOfMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Second</td>\n",
       "      <td>First</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1  Team2  Stadium  HostCountry Team1_Venue Team2_Venue Team1_Innings  \\\n",
       "0      2      4       34            1        Home        Away         First   \n",
       "1     14      1       19           15        Home        Away         First   \n",
       "2      9     10      130           14     Neutral     Neutral        Second   \n",
       "3      9     10        8            9        Home        Away         First   \n",
       "4      5     15      130           14     Neutral     Neutral         First   \n",
       "\n",
       "  Team2_Innings MonthOfMatch  \n",
       "0        Second          Oct  \n",
       "1        Second          Mar  \n",
       "2         First          Dec  \n",
       "3        Second          Dec  \n",
       "4        Second          Oct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First important learning from this hackathon is to convert this multi class classification to binary classification. Because predicting for other teams when team-1 is playing against team-2 doesn't make any sense. This helped me to get average cross validation score 0.61 from 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.MatchWinner == train.Team1 ,'MatchWinner']=0\n",
    "train.loc[train.MatchWinner == train.Team2,'MatchWinner']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train['train_or_test']='train'\n",
    "test['train_or_test']='test'\n",
    "df=pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     379\n",
       "5     318\n",
       "10    316\n",
       "14    262\n",
       "13    246\n",
       "12    245\n",
       "4     237\n",
       "9     223\n",
       "15     87\n",
       "2      70\n",
       "6      33\n",
       "0      27\n",
       "7      24\n",
       "11     18\n",
       "8      15\n",
       "3       8\n",
       "Name: MatchWinner, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['MatchWinner'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created Team Rank based on Team Winning Numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Team1':[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], 'Team1_Rank':['Rank_12','Rank_1','Rank_10','Rank_16','Rank_7','Rank_2','Rank_11','Rank_13','Rank_15','Rank_8','Rank_3','Rank_14','Rank_6','Rank_5','Rank_4','Rank_9']} \n",
    "team1rank=pd.DataFrame(data)\n",
    "data = {'Team2':[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], 'Team2_Rank':['Rank_12','Rank_1','Rank_10','Rank_16','Rank_7','Rank_2','Rank_11','Rank_13','Rank_15','Rank_8','Rank_3','Rank_14','Rank_6','Rank_5','Rank_4','Rank_9']} \n",
    "team2rank=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(team1rank,on='Team1',how='left')\n",
    "df=df.merge(team2rank,on='Team2',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got this useful code snippet from :https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering ,which calculates aggregate features based on numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Groups and aggregates the numeric values in a child dataframe\n",
    "    by the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the child dataframe to calculate the statistics on\n",
    "        parent_var (string): \n",
    "            the parent variable used for grouping and aggregating\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated by the `parent_var` for \n",
    "            all numeric columns. Each observation of the parent variable will have \n",
    "            one row in the dataframe with the parent variable as the index. \n",
    "            The columns are also renamed using the `df_name`. Columns with all duplicate\n",
    "            values are removed. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "            \n",
    "    # Only want the numeric variables\n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').drop(columns={'MatchWinner'}).copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = []\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    agg.columns = columns\n",
    "    \n",
    "    # Remove the columns with all redundant values\n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetaure selection technique is recomended after this. I had no time to work on itensive feature selection.All other features are tested individually with validation set .Removing/Adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous aggregation shape:  (16, 13)\n"
     ]
    }
   ],
   "source": [
    "previous_agg = agg_numeric(df, 'Team1', 'previous')\n",
    "print('Previous aggregation shape: ', previous_agg.shape)\n",
    "df=df.merge(previous_agg, on ='Team1', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous aggregation shape:  (16, 63)\n"
     ]
    }
   ],
   "source": [
    "previous_agg = agg_numeric(df, 'Team2', 'previous')\n",
    "print('Previous aggregation shape: ', previous_agg.shape)\n",
    "df=df.merge(previous_agg, on ='Team2', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This generates aggregate features on categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_categorical(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregates the categorical features in a child dataframe\n",
    "    for each observation of the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    parent_var : string\n",
    "        The variable by which to group and aggregate the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with aggregated statistics for each observation of the parent_var\n",
    "        The columns are also renamed and columns with duplicate values are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    # Remove duplicate columns by values\n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection technique is recomended after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous counts shape:  (16, 102)\n",
      "Previous counts shape:  (16, 102)\n"
     ]
    }
   ],
   "source": [
    "previous_counts = agg_categorical(df, 'Team1', 'previous')\n",
    "print('Previous counts shape: ', previous_counts.shape)\n",
    "previous_counts.head()\n",
    "df=df.merge(previous_counts, on ='Team1', how = 'left')\n",
    "\n",
    "previous_counts = agg_categorical(df, 'Team2', 'previous')\n",
    "print('Previous counts shape: ', previous_counts.shape)\n",
    "previous_counts.head()\n",
    "df=df.merge(previous_counts, on ='Team2', how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverting numerical columns as str to use it for inetraction features. LGBM works well with interaction features.\n",
    "#### Useful feature engineering tips from the winner:https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Team1']=df['Team1'].astype(str)\n",
    "df['Team2']=df['Team2'].astype(str)\n",
    "df['Stadium']=df['Stadium'].astype(str)\n",
    "df['HostCountry']=df['HostCountry'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction1=df['Team1']+'_'+df['Team2']\n",
    "interaction2=df['Team1']+'_'+df['HostCountry']\n",
    "\n",
    "interaction3=df['Team2']+'_'+df['Team1_Venue']\n",
    "interaction4=df['Team2']+'_'+df['Team2_Venue']\n",
    "\n",
    "df['T1_T2']=interaction1\n",
    "df['T1_H']=interaction2\n",
    "df['T2_T1V']=interaction3\n",
    "df['T2_T2V']=interaction4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HostCountry', 'MatchWinner', 'MonthOfMatch', 'Stadium', 'Team1',\n",
       "       'Team1_Innings', 'Team1_Venue', 'Team2', 'Team2_Innings', 'Team2_Venue',\n",
       "       ...\n",
       "       'previous_Team1_Innings_First_sum_y',\n",
       "       'previous_Team1_Innings_Second_sum_y',\n",
       "       'previous_train_or_test_train_sum_y',\n",
       "       'previous_Team2_Rank_Rank_12_sum_y', 'previous_Team1_Venue_Home_sum_y',\n",
       "       'previous_MonthOfMatch_Apr_count_y', 'T1_T2', 'T1_H', 'T2_T1V',\n",
       "       'T2_T2V'],\n",
       "      dtype='object', length=297)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in ['Team1_Innings','Team2_Innings', 'T1_T2','T2_T1V','T2_T2V']:\n",
    "    df[col]=  df[col].astype('str')\n",
    "    df[col]= le.fit_transform(df[col])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dict = {\"Home\":2,\"Away\":0,\"Neutral\":1}\n",
    "\n",
    "df[\"Team1_Venue\"] = df[\"Team1_Venue\"].map(venue_dict)\n",
    "df[\"Team2_Venue\"] = df[\"Team2_Venue\"].map(venue_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('Team1_Rank').size()) / len(df)\n",
    "df['Team1_Rank'] = df['Team1_Rank'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('Team2_Rank').size()) / len(df)\n",
    "df['Team2_Rank'] = df['Team2_Rank'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('MonthOfMatch').size()) / len(df)\n",
    "df['MonthOfMatch'] = df['MonthOfMatch'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('Team1').size()) / len(df)\n",
    "df['Team1_fe'] = df['Team1'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('Team2').size()) / len(df)\n",
    "df['Team2_fe'] = df['Team2'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('HostCountry').size()) / len(df)\n",
    "df['HostCountry_fe'] = df['HostCountry'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('T1_H').size()) / len(df)\n",
    "df['T1_H'] = df['T1_H'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pol = (df.groupby('T2_T2V').size()) / len(df)\n",
    "df['T2_T2V_fe'] = df['T2_T2V'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Team1']=df['Team1'].astype(int)\n",
    "df['Team2']=df['Team2'].astype(int)\n",
    "df['Stadium']=df['Stadium'].astype(int)\n",
    "df['HostCountry']=df['HostCountry'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Unique_Stadium_team1']=df.groupby(['Team1'])['Stadium'].transform('nunique')\n",
    "df['Unique_Stadium_team2']=df.groupby(['Team2'])['Stadium'].transform('nunique')\n",
    "\n",
    "df['Team1_unique_Team2']=df.groupby(['Team1'])['Team2'].transform('nunique')\n",
    "df['Team2_unique_Team1']=df.groupby(['Team2'])['Team1'].transform('nunique')\n",
    "\n",
    "df['Unique_Stadium_team1_team2']=df.groupby(['Team1','Team2'])['Stadium'].transform('nunique')\n",
    "\n",
    "#Noteuseful\n",
    "#df['Unique_Stadium_team1_team2']=df.groupby(['Team1'])['MonthOfMatch'].transform('nunique')\n",
    "#df['Unique_Country_team1']=df.groupby(['Team1'])['HostCountry'].transform('nunique')\n",
    "#df['Unique_Country_team2']=df.groupby(['Team2'])['HostCountry'].transform('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the number of Unique stadium a team played ,Genearted mapping as below. Generally Experienced team would have played in many stadium and new team would have  played in less stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67    551\n",
       "78    513\n",
       "53    370\n",
       "55    359\n",
       "45    359\n",
       "38    262\n",
       "33    259\n",
       "28    246\n",
       "35    205\n",
       "3     188\n",
       "21    115\n",
       "17     61\n",
       "14     36\n",
       "8      32\n",
       "11     27\n",
       "Name: Unique_Stadium_team1, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unique_Stadium_team1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "map={3:'VeryNewTeam',8:'NewTeam',11:'NewTeam',14:'NewTeam',17:'NewTeam',21:'Moderate',28:'Moderate',33:'Moderate',35:'Moderate',38:'Moderate',45:'Experienced',53:'Experienced',55:'Experienced',67:'HighlyExperienced',78:'HighlyExperienced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Team1_Experience']=df['Unique_Stadium_team1'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87    477\n",
       "92    475\n",
       "81    467\n",
       "67    335\n",
       "88    315\n",
       "76    297\n",
       "71    287\n",
       "70    281\n",
       "89    277\n",
       "49    116\n",
       "21     92\n",
       "41     68\n",
       "17     61\n",
       "24     35\n",
       "Name: Unique_Stadium_team2, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unique_Stadium_team2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "map={17:'NewTeamT2',21:'NewTeamT2',24:'NewTeamT2',41:'ModerateT2',49:'ExperiencedT2',67:'HighlyExperiencedT2',70:'HighlyExperiencedT2',71:'HighlyExperiencedT2',76:'HighlyExperiencedT2',81:'HighlyExperiencedT2',87:'HighlyExperiencedT2',88:'HighlyExperiencedT2',89:'HighlyExperiencedT2',92:'HighlyExperiencedT2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Team2_Experience']=df['Unique_Stadium_team2'].map(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OHE above 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Team1_Experience','Team2_Experience']:\n",
    "    df = pd.get_dummies(df, columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting back train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=df.loc[df.train_or_test.isin(['train'])]\n",
    "test=df.loc[df.train_or_test.isin(['test'])]\n",
    "train.drop(columns={'train_or_test'},axis=1,inplace=True)\n",
    "test.drop(columns={'train_or_test'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the below fetaures are target based features, which i thought was working well initially. One has to be careful while generating target based Feature.\n",
    "#### This was the most importatnt learning from this hackathon. One has to validate this with validation set ,by setting validating target as NA ,macthing to the test data.\n",
    "#### Since validation data already knows the actual target ,  features  generated will be based on its own target and your model will predict good and so the accuracy increases.\n",
    "#### On the other side ,test set doesnt have the target feature ,and target based feature is from the aggregate of trian data.\n",
    "#### When i set validation target as NA,I got the clear picture that cze of data leakage these features were performing well, so i ignored all the below target based features[This validation is not shown in the code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Learning] https://www.kaggle.com/abhilashawasthi/feature-engineering-lgb-model - this is a time series problem where the author fills validation target as NA before generating target based feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf = train.groupby([\"Team1\",\"Team2\"])[\"MatchWinner\"].count().reset_index()\n",
    "#gdf.columns = [\"Team1\", \"Team2\",\"Team1_against_Team2\"]\n",
    "#train = train.merge(gdf, on=[\"Team1\",\"Team2\"], how=\"left\")\n",
    "#test = test.merge(gdf, on=[\"Team1\",\"Team2\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['Team1_won']=0\n",
    "#for i in range(len(train)):\n",
    "    #if train.loc[i,'Team1']==train.loc[i,'MatchWinner']:\n",
    "        #train.loc[i,'Team1_won']=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##P.S: Name convention are #not proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1win = train.groupby(['Team1', 'Team2','Stadium']).agg({'Team1_won': ['mean']})\n",
    "# Team1win.columns = ['grpd_by_Product_Brand_Day_' + '_'.join(c).strip('_') for c in Team1win.columns] \n",
    "# train = train.merge(Team1win, on=[\"Team1\",\"Team2\",\"Stadium\"], how=\"left\")\n",
    "# test = test.merge(Team1win, on=[\"Team1\",\"Team2\",\"Stadium\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1win = train.groupby(['Team1', 'Team2','HostCountry']).agg({'Team1_won': ['mean']})\n",
    "# Team1win.columns = ['grpd_by_team1_' + '_'.join(c).strip('_') for c in Team1win.columns]\n",
    "# train = train.merge(Team1win, on=[\"Team1\",\"Team2\",'HostCountry'], how=\"left\")\n",
    "# test = test.merge(Team1win, on=[\"Team1\",\"Team2\",'HostCountry'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1win = train.groupby(['Team1', 'Team2','Team1_Innings']).agg({'Team1_won': ['mean']})\n",
    "# Team1win.columns = ['grpd_by_team1_venue' + '_'.join(c).strip('_') for c in Team1win.columns]\n",
    "# #train = train.merge(Team1win, on=[\"Team1\",\"Team2\",'Team1_Innings'], how=\"left\")\n",
    "# #test = test.merge(Team1win, on=[\"Team1\",\"Team2\",'Team1_Innings'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1win = train.groupby(['Team1', 'Team2','MonthOfMatch']).agg({'Team1_won': ['mean']})\n",
    "# Team1win.columns = ['grpd_by_team1_month' + '_'.join(c).strip('_') for c in Team1win.columns]\n",
    "# train = train.merge(Team1win, on=[\"Team1\",\"Team2\",'MonthOfMatch'], how=\"left\")\n",
    "# test = test.merge(Team1win, on=[\"Team1\",\"Team2\",'MonthOfMatch'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initially since numeric feat were overfitting ,tried to map it as categorical col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[ train['grpd_by_team1_monthTeam1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_month'] = 'Very_Less_Chance'\n",
    "# train.loc[(train['grpd_by_team1_monthTeam1_won_mean'] > 0.0) & (train['grpd_by_team1_monthTeam1_won_mean'] <0.50), 'Team1_Winning_against_Team2_month'] = 'less_chance'\n",
    "# train.loc[train['grpd_by_team1_monthTeam1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_month'] = 'Equal_Chance'\n",
    "# train.loc[(train['grpd_by_team1_monthTeam1_won_mean'] > 0.50) & (train['grpd_by_team1_monthTeam1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_month'] = 'Good_Chance'\n",
    "# train.loc[train['grpd_by_team1_monthTeam1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_month'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[ test['grpd_by_team1_monthTeam1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_month'] = 'Very_Less_Chance'\n",
    "# test.loc[(test['grpd_by_team1_monthTeam1_won_mean'] > 0.0) & (test['grpd_by_team1_monthTeam1_won_mean'] <0.50), 'Team1_Winning_against_Team2_month'] = 'less_chance'\n",
    "# test.loc[test['grpd_by_team1_monthTeam1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_month'] = 'Equal_Chance'\n",
    "# test.loc[(test['grpd_by_team1_monthTeam1_won_mean'] > 0.50) & (test['grpd_by_team1_monthTeam1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_month'] = 'Good_Chance'\n",
    "# test.loc[test['grpd_by_team1_monthTeam1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_month'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Team1_Winning_against_Team2_month'].fillna(-99,inplace=True)\n",
    "# fe_pol = (train.groupby('Team1_Winning_against_Team2_month').size()) / len(train)\n",
    "# train['Team1_Winning_against_Team2_month'] = train['Team1_Winning_against_Team2_month'].apply(lambda x : fe_pol[x])\n",
    "# fe_pol = (test.groupby('Team1_Winning_against_Team2_month').size()) / len(test)\n",
    "# test['Team1_Winning_against_Team2_month'] = test['Team1_Winning_against_Team2_month'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[ train['grpd_by_team1_venueTeam1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_venue'] = 'Very_Less_Chance'\n",
    "# train.loc[(train['grpd_by_team1_venueTeam1_won_mean'] > 0.0) & (train['grpd_by_team1_venueTeam1_won_mean'] <0.50), 'Team1_Winning_against_Team2_venue'] = 'less_chance'\n",
    "# train.loc[train['grpd_by_team1_venueTeam1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_venue'] = 'Equal_Chance'\n",
    "# train.loc[(train['grpd_by_team1_venueTeam1_won_mean'] > 0.50) & (train['grpd_by_team1_venueTeam1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_venue'] = 'Good_Chance'\n",
    "# train.loc[train['grpd_by_team1_venueTeam1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_venue'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[ test['grpd_by_team1_venueTeam1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_venue'] = 'Very_Less_Chance'\n",
    "# test.loc[(test['grpd_by_team1_venueTeam1_won_mean'] > 0.0) & (test['grpd_by_team1_venueTeam1_won_mean'] <0.50), 'Team1_Winning_against_Team2_venue'] = 'less_chance'\n",
    "# test.loc[test['grpd_by_team1_venueTeam1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_venue'] = 'Equal_Chance'\n",
    "# test.loc[(test['grpd_by_team1_venueTeam1_won_mean'] > 0.50) & (test['grpd_by_team1_venueTeam1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_venue'] = 'Good_Chance'\n",
    "# test.loc[test['grpd_by_team1_venueTeam1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_venue'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Team1_Winning_against_Team2_venue'].fillna(-99,inplace=True)\n",
    "# fe_pol = (train.groupby('Team1_Winning_against_Team2_venue').size()) / len(train)\n",
    "# train['Team1_Winning_against_Team2_venue'] = train['Team1_Winning_against_Team2_venue'].apply(lambda x : fe_pol[x])\n",
    "# fe_pol = (test.groupby('Team1_Winning_against_Team2_venue').size()) / len(test)\n",
    "# test['Team1_Winning_against_Team2_venue'] = test['Team1_Winning_against_Team2_venue'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[ train['grpd_by_team1_Team1_won_mean'] == 0.0, 'Team1_Winning_against_Team2'] = 'Very_Less_Chance'\n",
    "# train.loc[(train['grpd_by_team1_Team1_won_mean'] > 0.0) & (train['grpd_by_team1_Team1_won_mean'] <0.50), 'Team1_Winning_against_Team2'] = 'less_chance'\n",
    "# train.loc[train['grpd_by_team1_Team1_won_mean'] == 0.50, 'Team1_Winning_against_Team2'] = 'Equal_Chance'\n",
    "# train.loc[(train['grpd_by_team1_Team1_won_mean'] > 0.50) & (train['grpd_by_team1_Team1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2'] = 'Good_Chance'\n",
    "# train.loc[train['grpd_by_team1_Team1_won_mean'] ==1.0, 'Team1_Winning_against_Team2'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[ test['grpd_by_team1_Team1_won_mean'] == 0.0, 'Team1_Winning_against_Team2'] = 'Very_Less_Chance'\n",
    "# test.loc[(test['grpd_by_team1_Team1_won_mean'] > 0.0) & (test['grpd_by_team1_Team1_won_mean'] <0.50), 'Team1_Winning_against_Team2'] = 'less_chance'\n",
    "# test.loc[test['grpd_by_team1_Team1_won_mean'] == 0.50, 'Team1_Winning_against_Team2'] = 'Equal_Chance'\n",
    "# test.loc[(test['grpd_by_team1_Team1_won_mean'] > 0.50) & (test['grpd_by_team1_Team1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2'] = 'Good_Chance'\n",
    "# test.loc[test['grpd_by_team1_Team1_won_mean'] ==1.0, 'Team1_Winning_against_Team2'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Team1_Winning_against_Team2'].fillna(-99,inplace=True)\n",
    "# fe_pol = (train.groupby('Team1_Winning_against_Team2').size()) / len(train)\n",
    "# train['Team1_Winning_against_Team2'] = train['Team1_Winning_against_Team2'].apply(lambda x : fe_pol[x])\n",
    "# fe_pol = (test.groupby('Team1_Winning_against_Team2').size()) / len(test)\n",
    "# test['Team1_Winning_against_Team2'] = test['Team1_Winning_against_Team2'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[ train['grpd_by_Product_Brand_Day_Team1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_in_Stadium'] = 'Very_Less_Chance'\n",
    "# train.loc[(train['grpd_by_Product_Brand_Day_Team1_won_mean'] > 0.0) & (train['grpd_by_Product_Brand_Day_Team1_won_mean'] <0.50), 'Team1_Winning_against_Team2_in_Stadium'] = 'less_chance'\n",
    "# train.loc[train['grpd_by_Product_Brand_Day_Team1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_in_Stadium'] = 'Equal_Chance'\n",
    "# train.loc[(train['grpd_by_Product_Brand_Day_Team1_won_mean'] > 0.50) & (train['grpd_by_Product_Brand_Day_Team1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_in_Stadium'] = 'Good_Chance'\n",
    "# train.loc[train['grpd_by_Product_Brand_Day_Team1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_in_Stadium'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[ test['grpd_by_Product_Brand_Day_Team1_won_mean'] == 0.0, 'Team1_Winning_against_Team2_in_Stadium'] = 'Very_Less_Chance'\n",
    "# test.loc[(test['grpd_by_Product_Brand_Day_Team1_won_mean'] > 0.0) & (test['grpd_by_Product_Brand_Day_Team1_won_mean'] <0.50), 'Team1_Winning_against_Team2_in_Stadium'] = 'less_chance'\n",
    "# test.loc[test['grpd_by_Product_Brand_Day_Team1_won_mean'] == 0.50, 'Team1_Winning_against_Team2_in_Stadium'] = 'Equal_Chance'\n",
    "# test.loc[(test['grpd_by_Product_Brand_Day_Team1_won_mean'] > 0.50) & (test['grpd_by_Product_Brand_Day_Team1_won_mean'] <= 0.99), 'Team1_Winning_against_Team2_in_Stadium'] = 'Good_Chance'\n",
    "# test.loc[test['grpd_by_Product_Brand_Day_Team1_won_mean'] ==1.0, 'Team1_Winning_against_Team2_in_Stadium'] = 'High_Chance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Team1_Winning_against_Team2_in_Stadium'].fillna(-99,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_pol = (train.groupby('Team1_Winning_against_Team2_in_Stadium').size()) / len(train)\n",
    "# train['Team1_Winning_against_Team2_in_Stadium'] = train['Team1_Winning_against_Team2_in_Stadium'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe_pol = (test.groupby('Team1_Winning_against_Team2_in_Stadium').size()) / len(test)\n",
    "# test['Team1_Winning_against_Team2_in_Stadium'] = test['Team1_Winning_against_Team2_in_Stadium'].apply(lambda x : fe_pol[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team1winstadium = train.groupby(['Team1', 'Team2','Stadium']).agg({'Team1_won': ['mean']})\n",
    "# Team1winstadium.columns = ['grpd_by_Product_Brand_Day_' + '_'.join(c).strip('_') for c in Team1win.columns]\n",
    "# train = train.merge(Team1winstadium, on=[\"Team1\",\"Team2\",'Stadium'], how=\"left\")\n",
    "# test = test.merge(Team1winstadium, on=[\"Team1\",\"Team2\",'Stadium'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train['Team1_won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train.drop(columns={'MatchWinner',#'T1_T2'\n",
    "                     },axis=1)\n",
    "y=train.loc[:,['MatchWinner']]\n",
    "test=test.drop(columns={'MatchWinner',#'T1_T2'\n",
    "                       },axis=1)\n",
    "testmain=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's binary_logloss: 0.575725\tvalid_1's binary_logloss: 0.598383\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's binary_logloss: 0.574664\tvalid_1's binary_logloss: 0.597642\n",
      "1  err_lgm:  0.5976420505710122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's binary_logloss: 0.577205\tvalid_1's binary_logloss: 0.588539\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's binary_logloss: 0.57398\tvalid_1's binary_logloss: 0.58779\n",
      "2  err_lgm:  0.5877902128186612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's binary_logloss: 0.574764\tvalid_1's binary_logloss: 0.597979\n",
      "[400]\ttraining's binary_logloss: 0.562449\tvalid_1's binary_logloss: 0.599005\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttraining's binary_logloss: 0.567589\tvalid_1's binary_logloss: 0.597026\n",
      "3  err_lgm:  0.597026090352419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's binary_logloss: 0.574061\tvalid_1's binary_logloss: 0.60403\n",
      "[400]\ttraining's binary_logloss: 0.561903\tvalid_1's binary_logloss: 0.599476\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's binary_logloss: 0.560118\tvalid_1's binary_logloss: 0.599021\n",
      "4  err_lgm:  0.5990227103811417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's binary_logloss: 0.574895\tvalid_1's binary_logloss: 0.612228\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttraining's binary_logloss: 0.569948\tvalid_1's binary_logloss: 0.610585\n",
      "5  err_lgm:  0.6105849158938431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5984131960034154"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "err = [] \n",
    "y_pred_tot_lgb = []\n",
    "l=[]\n",
    "\n",
    "\n",
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in fold.split(x, y):\n",
    "    x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    m = LGBMClassifier(\n",
    "                       max_depth=2,\n",
    "                       num_leaves=5,\n",
    "                       learning_rate=0.08,\n",
    "                       n_estimators=3000,\n",
    "                       min_data_in_leaf = 95,\n",
    "                       feature_fraction = 0.05,\n",
    "                       min_child_weight=5,\n",
    "                       min_child_samples=15,\n",
    "                       colsample_bytree=0.15,\n",
    "                       reg_alpha=0.5,\n",
    "                       reg_lambda=2,\n",
    "                       random_state=2020\n",
    "                       )\n",
    "    m.fit(x_train, y_train,eval_set=[(x_train,y_train),(x_val, y_val)],early_stopping_rounds=100, verbose=200)\n",
    "    pred_y = m.predict_proba(x_val)\n",
    "    pred_y=np.clip(pred_y,0.025,0.975)\n",
    "    feature_importances = pd.DataFrame(m.feature_importances_,\n",
    "                                       index = x.columns,\n",
    "                                        columns=['importance'])\n",
    "    sum=feature_importances.values\n",
    "    l.append(sum)\n",
    "    print(i, \" err_lgm: \", log_loss(y_val,pred_y))\n",
    "    err.append(log_loss(y_val,pred_y))\n",
    "    pred_test = m.predict_proba(test)\n",
    "    i = i + 1\n",
    "    y_pred_tot_lgb.append(pred_test)\n",
    "(err[0]+err[1]+err[2]+err[3]+err[4])/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABetta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "m = LGBMClassifier(max_depth=2,\n",
    "                   num_leaves=5,\n",
    "                   learning_rate=0.08,\n",
    "                   n_estimators=300,\n",
    "                   min_data_in_leaf = 95,\n",
    "                   feature_fraction = 0.05,\n",
    "                   min_child_weight=5,\n",
    "                   min_child_samples=15,\n",
    "                   colsample_bytree=0.15,\n",
    "                   reg_alpha=0.5,\n",
    "                   reg_lambda=2,\n",
    "                   random_state=2020)\n",
    "m.fit(x,y)\n",
    "pred =m.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.clip(0.025,0.975) #https://medium.com/@egor_vorobiev/how-to-improve-log-loss-score-kaggle-trick-3f95577839f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=sub.clip(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=test.loc[:,['Team1','Team2']]\n",
    "test1.reset_index(drop=True,inplace=True)\n",
    "test1=test1.join(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test1)):\n",
    "    pos=test1.loc[i,'Team1']\n",
    "    pos1=test1.loc[i,'Team2']\n",
    "    sub.loc[i,pos]=test1.loc[i,0]\n",
    "    sub.loc[i,pos1]=test1.loc[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_excel('lgbmbinary.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
